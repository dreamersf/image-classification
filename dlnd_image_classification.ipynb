{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 图像分类\n",
    "\n",
    "在此项目中，你将对 [CIFAR-10 数据集](https://www.cs.toronto.edu/~kriz/cifar.html) 中的图片进行分类。该数据集包含飞机、猫狗和其他物体。你需要预处理这些图片，然后用所有样本训练一个卷积神经网络。图片需要标准化（normalized），标签需要采用 one-hot 编码。你需要应用所学的知识构建卷积的、最大池化（max pooling）、丢弃（dropout）和完全连接（fully connected）的层。最后，你需要在样本图片上看到神经网络的预测结果。\n",
    "\n",
    "\n",
    "## 获取数据\n",
    "\n",
    "请运行以下单元，以下载 [CIFAR-10 数据集（Python版）](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "from sklearn import preprocessing\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "# Use Floyd's cifar-10 dataset if present\n",
    "floyd_cifar10_location = '/input/cifar-10/python.tar.gz'\n",
    "if isfile(floyd_cifar10_location):\n",
    "    tar_gz_path = floyd_cifar10_location\n",
    "else:\n",
    "    tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 探索数据\n",
    "\n",
    "该数据集分成了几部分／批次（batches），以免你的机器在计算时内存不足。CIFAR-10 数据集包含 5 个部分，名称分别为 `data_batch_1`、`data_batch_2`，以此类推。每个部分都包含以下某个类别的标签和图片：\n",
    "\n",
    "* 飞机\n",
    "* 汽车\n",
    "* 鸟类\n",
    "* 猫\n",
    "* 鹿\n",
    "* 狗\n",
    "* 青蛙\n",
    "* 马\n",
    "* 船只\n",
    "* 卡车\n",
    "\n",
    "了解数据集也是对数据进行预测的必经步骤。你可以通过更改 `batch_id` 和 `sample_id` 探索下面的代码单元。`batch_id` 是数据集一个部分的 ID（1 到 5）。`sample_id` 是该部分中图片和标签对（label pair）的 ID。\n",
    "\n",
    "问问你自己：“可能的标签有哪些？”、“图片数据的值范围是多少？”、“标签是按顺序排列，还是随机排列的？”。思考类似的问题，有助于你预处理数据，并使预测结果更准确。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 5:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1014, 1: 1014, 2: 952, 3: 1016, 4: 997, 5: 1025, 6: 980, 7: 977, 8: 1003, 9: 1022}\n",
      "First 20 Labels: [1, 8, 5, 1, 5, 7, 4, 3, 8, 2, 7, 2, 0, 1, 5, 9, 6, 2, 0, 8]\n",
      "\n",
      "Example of Image 0:\n",
      "Image - Min Value: 2 Max Value: 255\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 1 Name: automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e5b2748>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 5\n",
    "sample_id = 0\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现预处理函数\n",
    "\n",
    "### 标准化\n",
    "\n",
    "在下面的单元中，实现 `normalize` 函数，传入图片数据 `x`，并返回标准化 Numpy 数组。值应该在 0 到 1 的范围内（含 0 和 1）。返回对象应该和 `x` 的形状一样。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement \n",
    "    return (x - np.min(x))/(np.max(x)-np.min(x))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot 编码\n",
    "\n",
    "和之前的代码单元一样，你将为预处理实现一个函数。这次，你将实现 `one_hot_encode` 函数。输入，也就是 `x`，是一个标签列表。实现该函数，以返回为 one_hot 编码的 Numpy 数组的标签列表。标签的可能值为 0 到 9。每次调用 `one_hot_encode` 时，对于每个值，one_hot 编码函数应该返回相同的编码。确保将编码映射保存到该函数外面。\n",
    "\n",
    "提示：不要重复发明轮子。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    #创建one hot 编码器\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    #分配变量\n",
    "    lb.fit(range(10))\n",
    "   # print(type(aa))\n",
    "    #转换\n",
    "    onehot1 = lb.transform(x)\n",
    "    onehot1 = np.array(onehot1)\n",
    "    return onehot1\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机化数据\n",
    "\n",
    "之前探索数据时，你已经了解到，样本的顺序是随机的。再随机化一次也不会有什么关系，但是对于这个数据集没有必要。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预处理所有数据并保存\n",
    "\n",
    "运行下方的代码单元，将预处理所有 CIFAR-10 数据，并保存到文件中。下面的代码还使用了 10% 的训练数据，用来验证。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查点\n",
    "\n",
    "这是你的第一个检查点。如果你什么时候决定再回到该记事本，或需要重新启动该记事本，你可以从这里开始。预处理的数据已保存到本地。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建网络\n",
    "\n",
    "对于该神经网络，你需要将每层都构建为一个函数。你看到的大部分代码都位于函数外面。要更全面地测试你的代码，我们需要你将每层放入一个函数中。这样使我们能够提供更好的反馈，并使用我们的统一测试检测简单的错误，然后再提交项目。\n",
    "\n",
    ">**注意**：如果你觉得每周很难抽出足够的时间学习这门课程，我们为此项目提供了一个小捷径。对于接下来的几个问题，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 程序包中的类来构建每个层级，但是“卷积和最大池化层级”部分的层级除外。TF Layers 和 Keras 及 TFLearn 层级类似，因此很容易学会。\n",
    "\n",
    ">但是，如果你想充分利用这门课程，请尝试自己解决所有问题，不使用 TF Layers 程序包中的任何类。你依然可以使用其他程序包中的类，这些类和你在 TF Layers 中的类名称是一样的！例如，你可以使用 TF Neural Network 版本的 `conv2d` 类 [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d)，而不是 TF Layers 版本的 `conv2d` 类 [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d)。\n",
    "\n",
    "我们开始吧！\n",
    "\n",
    "\n",
    "### 输入\n",
    "\n",
    "神经网络需要读取图片数据、one-hot 编码标签和丢弃保留概率（dropout keep probability）。请实现以下函数：\n",
    "\n",
    "* 实现 `neural_net_image_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * 使用 `image_shape` 设置形状，部分大小设为 `None`\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"x\" 命名\n",
    "* 实现 `neural_net_label_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * 使用 `n_classes` 设置形状，部分大小设为 `None`\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"y\" 命名\n",
    "* 实现 `neural_net_keep_prob_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)，用于丢弃保留概率\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"keep_prob\" 命名\n",
    "\n",
    "这些名称将在项目结束时，用于加载保存的模型。\n",
    "\n",
    "注意：TensorFlow 中的 `None` 表示形状可以是动态大小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "#     print('image_shape',image_shape[0],image_shape[1],image_shape[2])\n",
    "    #32 * 32 * 3\n",
    "#     x = tf.placeholder(tf.string)\n",
    "    input1= tf.placeholder(\n",
    "         tf.float32,\n",
    "         name='x',\n",
    "         shape=[None,*image_shape])\n",
    "    return input1\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "#     print('n_classes',n_classes)\n",
    "    # TODO: Implement Function)\n",
    "    input1= tf.placeholder(\n",
    "         tf.float32,\n",
    "         name='y',\n",
    "         shape=[None,n_classes])\n",
    "    return input1\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32,\n",
    "                          name='keep_prob')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积和最大池化层\n",
    "\n",
    "卷积层级适合处理图片。对于此代码单元，你应该实现函数 `conv2d_maxpool` 以便应用卷积然后进行最大池化：\n",
    "\n",
    "* 使用 `conv_ksize`、`conv_num_outputs` 和 `x_tensor` 的形状创建权重（weight）和偏置（bias）。\n",
    "* 使用权重和 `conv_strides` 对 `x_tensor` 应用卷积。\n",
    " * 建议使用我们建议的间距（padding），当然也可以使用任何其他间距。\n",
    "* 添加偏置\n",
    "* 向卷积中添加非线性激活（nonlinear activation）\n",
    "* 使用 `pool_ksize` 和 `pool_strides` 应用最大池化\n",
    " * 建议使用我们建议的间距（padding），当然也可以使用任何其他间距。\n",
    "\n",
    "**注意**：对于**此层**，**请勿使用** [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers)，但是仍然可以使用 TensorFlow 的 [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) 包。对于所有**其他层**，你依然可以使用快捷方法。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "   # print('x_tensor',x_tensor, '\\nconv_num_outputs',conv_num_outputs, '\\nconv_ksize',conv_ksize,\n",
    "    #      '\\nconv_strides',conv_strides, '\\npool_ksize',pool_ksize, '\\npool_strides',pool_strides)\n",
    "\n",
    "    # x_tensor Tensor(\"Placeholder:0\", shape=(?, 32, 32, 5), dtype=float32) \n",
    "    # conv_num_outputs 10 \n",
    "    # conv_ksize (2, 2) \n",
    "    # conv_strides (4, 4) \n",
    "    # pool_ksize (2, 2) \n",
    "    # pool_strides (2, 2)\n",
    "    # TODO: Implement Function\n",
    "    #使用 conv_ksize、conv_num_outputs 和 x_tensor 的形状创建权重（weight）和偏置（bias）。\n",
    "   # print(conv_ksize[0],conv_ksize[1],conv_num_outputs,x_tensor.shape[3])\n",
    "    weight = tf.Variable(tf.truncated_normal(\n",
    "        [conv_ksize[0],conv_ksize[1],(int)(x_tensor.shape[3]),conv_num_outputs],\n",
    "        stddev=0.1))\n",
    "    #print('weight',weight)\n",
    "#     return\n",
    "    bias = tf.Variable(tf.zeros(conv_num_outputs))\n",
    "    #使用权重和 conv_strides 对 x_tensor 应用卷积。\n",
    "    conv_layer = tf.nn.conv2d(x_tensor,weight,strides=[1,conv_strides[0],conv_strides[1],1],padding='SAME')\n",
    "    #'添加偏置'\n",
    "    conv_layer = tf.nn.bias_add(conv_layer,bias)\n",
    "    #向卷积中添加非线性激活（nonlinear activation）\n",
    "    conv_layer = tf.nn.relu(conv_layer)\n",
    "#     print('conv_layer',conv_layer)\n",
    "    #使用 pool_ksize 和 pool_strides 应用最大池化\n",
    "    #建议使用我们建议的间距（padding），当然也可以使用任何其他间距。\n",
    "    pool = tf.nn.max_pool(conv_layer,[1,pool_ksize[0],pool_ksize[1],1],[1,pool_strides[0],pool_strides[1],1],'VALID')\n",
    "#     print('pool',pool)\n",
    "    #pool Tensor(\"MaxPool_5:0\", shape=(?, 4, 4, 10), dtype=float32)\n",
    "    return pool \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 扁平化层\n",
    "\n",
    "实现 `flatten` 函数，将 `x_tensor` 的维度从四维张量（4-D tensor）变成二维张量。输出应该是形状（*部分大小（Batch Size）*，*扁平化图片大小（Flattened Image Size）*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    #print(x_tensor,x_tensor.shape[1]*x_tensor.shape[2]*x_tensor.shape[3])\n",
    "    \n",
    "   # aa = tf.reshape(x_tensor,[-1,int(x_tensor.shape[1]*x_tensor.shape[2]*x_tensor.shape[3])])\n",
    "   # print(aa)\n",
    "#     tf(batch_size\n",
    "    #Tensor(\"Reshape_7:0\", shape=(?, 1800), dtype=float32)\n",
    "    return tf.reshape(x_tensor,[-1,int(x_tensor.shape[1]*x_tensor.shape[2]*x_tensor.shape[3])])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 完全连接的层\n",
    "\n",
    "实现 `fully_conn` 函数，以向 `x_tensor` 应用完全连接的层级，形状为（*部分大小（Batch Size）*，*num_outputs*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "   # print(x_tensor, num_outputs)\n",
    "    #Tensor(\"Placeholder:0\", shape=(?, 128), dtype=float32) 40\n",
    "    weight = tf.Variable(tf.truncated_normal([int(x_tensor.shape[1]),num_outputs],stddev=0.1))\n",
    "    #print('weight',weight)\n",
    "#     return\n",
    "    bias = tf.Variable(tf.zeros(num_outputs))\n",
    "    #print('x_tensor',x_tensor,'num_outputs',num_outputs)\n",
    "    #x_tensor Tensor(\"Placeholder_51:0\", shape=(?, 128), dtype=float32) num_outputs 40\n",
    "    #Tensor(\"Add_1:0\", shape=(?, 40), dtype=float32)\n",
    "    return tf.nn.relu(tf.add(tf.matmul(x_tensor,weight),bias))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输出层\n",
    "\n",
    "实现 `output` 函数，向 x_tensor 应用完全连接的层级，形状为（*部分大小（Batch Size）*，*num_outputs*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。\n",
    "\n",
    "**注意**：该层级不应应用 Activation、softmax 或交叉熵（cross entropy）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    weight = tf.Variable(tf.truncated_normal([int(x_tensor.shape[1]),num_outputs],stddev=0.1))\n",
    "#     bias = tf.Variable(tf.truncated_normal([num_outputs],-0.1,0.1))\n",
    "    bias = tf.Variable(tf.zeros(num_outputs))\n",
    "    #print('x_tensor',x_tensor, ', num_outputs',num_outputs)\n",
    "    #x_tensor Tensor(\"Placeholder_57:0\", shape=(?, 128), dtype=float32) , num_outputs 40\n",
    "    #temp = tf.add(tf.matmul(x_tensor,weight),bias)\n",
    "    #print(temp)\n",
    "    #Tensor(\"Add_5:0\", shape=(?, 40), dtype=float32)\n",
    "    return tf.nn.relu(tf.add(tf.matmul(x_tensor,weight),bias))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建卷积模型\n",
    "\n",
    "实现函数 `conv_net`， 创建卷积神经网络模型。该函数传入一批图片 `x`，并输出对数（logits）。使用你在上方创建的层创建此模型：\n",
    "\n",
    "* 应用 1、2 或 3 个卷积和最大池化层（Convolution and Max Pool layers）\n",
    "* 应用一个扁平层（Flatten Layer）\n",
    "* 应用 1、2 或 3 个完全连接层（Fully Connected Layers）\n",
    "* 应用一个输出层（Output Layer）\n",
    "* 返回输出\n",
    "* 使用 `keep_prob` 向模型中的一个或多个层应用 [TensorFlow 的 Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    \n",
    "    #print(x,keep_prob)\n",
    "    #Tensor(\"x:0\", shape=(?, 32, 32, 3), dtype=float32) Tensor(\"keep_prob:0\", dtype=float32)\n",
    "    conv_num_outputs = 64\n",
    "    conv_ksize =[4,4]\n",
    "    conv_strides=[2,2]\n",
    "    pool_ksize=[2,2]\n",
    "    pool_strides=[2,2]\n",
    "    \n",
    "    conv = conv2d_maxpool(x,conv_num_outputs,conv_ksize,conv_strides,pool_ksize,pool_strides)\n",
    "    \n",
    "    conv_num_outputs = 128\n",
    "    conv = conv2d_maxpool(conv,conv_num_outputs,conv_ksize,conv_strides,pool_ksize,pool_strides)\n",
    "\n",
    "    flat = flatten(conv)\n",
    "    \n",
    "    num_outputs = 256\n",
    "    fullyconn = fully_conn(flat,num_outputs)\n",
    "    num_outputs = 128\n",
    "    fullyconn = fully_conn(fullyconn,num_outputs)\n",
    "    num_outputs = 10\n",
    "    fullyconn = fully_conn(fullyconn,num_outputs)\n",
    "#     print('fullyconn',fullyconn)\n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    fullyconn = tf.nn.dropout(fullyconn, keep_prob)\n",
    "    out = output(fullyconn,num_outputs)\n",
    "#     print('out',out)\n",
    "    # TODO: return output\n",
    "#     conv Tensor(\"MaxPool:0\", shape=(?, 8, 8, 10), dtype=float32)\n",
    "#     flat Tensor(\"Reshape:0\", shape=(?, 640), dtype=float32)\n",
    "#     fullyconn Tensor(\"Relu_1:0\", shape=(?, 10), dtype=float32)\n",
    "#     out Tensor(\"Add_1:0\", shape=(?, 10), dtype=float32)\n",
    "    return out\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "# print('----logits',logits)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练神经网络\n",
    "\n",
    "### 单次优化\n",
    "\n",
    "实现函数 `train_neural_network` 以进行单次优化（single optimization）。该优化应该使用 `optimizer` 优化 `session`，其中 `feed_dict` 具有以下参数：\n",
    "\n",
    "* `x` 表示图片输入\n",
    "* `y` 表示标签\n",
    "* `keep_prob` 表示丢弃的保留率\n",
    "\n",
    "每个部分都会调用该函数，所以 `tf.global_variables_initializer()` 已经被调用。\n",
    "\n",
    "注意：不需要返回任何内容。该函数只是用来优化神经网络。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    #print('session',session, 'optimizer',optimizer, 'keep_probability',keep_probability, 'feature_batch',feature_batch[0][0], 'label_batch',label_batch[0][0])\n",
    "    #session <tensorflow.python.client.session.Session object at 0x11d0a0e48> \n",
    "    #optimizer <tensorflow.python.training.adam.AdamOptimizer object at 0x11cee79b0>\n",
    "    #keep_probability [ 0.37902941] \n",
    "    session.run(optimizer,feed_dict={\n",
    "        x:feature_batch,\n",
    "        y:label_batch,\n",
    "        keep_prob:keep_probability\n",
    "    })\n",
    "    pass\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 显示数据\n",
    "\n",
    "实现函数 `print_stats` 以输出损失和验证准确率。使用全局变量 `valid_features` 和 `valid_labels` 计算验证准确率。使用保留率 `1.0` 计算损失和验证准确率（loss and validation accuracy）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    loss = sess.run(cost, feed_dict={\n",
    "                x: feature_batch,\n",
    "                y: label_batch,\n",
    "                keep_prob: 1.})\n",
    "    valid_acc = sess.run(accuracy, feed_dict={\n",
    "        x: valid_features,\n",
    "        y: valid_labels,\n",
    "        keep_prob: 1.})\n",
    "\n",
    "    print('Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(\n",
    "        loss,\n",
    "        valid_acc))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 超参数\n",
    "\n",
    "调试以下超参数：\n",
    "* 设置 `epochs` 表示神经网络停止学习或开始过拟合的迭代次数\n",
    "* 设置 `batch_size`，表示机器内存允许的部分最大体积。大部分人设为以下常见内存大小：\n",
    "\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* 设置 `keep_probability` 表示使用丢弃时保留节点的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 70\n",
    "#内存\n",
    "batch_size = 256\n",
    "#只对开始值有直接影响\n",
    "keep_probability = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在单个 CIFAR-10 部分上训练\n",
    "\n",
    "我们先用单个部分，而不是用所有的 CIFAR-10 批次训练神经网络。这样可以节省时间，并对模型进行迭代，以提高准确率。最终验证准确率达到 50% 或以上之后，在下一部分对所有数据运行模型。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:     2.2710 Validation Accuracy: 0.171800\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:     2.2480 Validation Accuracy: 0.265000\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:     2.2079 Validation Accuracy: 0.285000\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:     2.1535 Validation Accuracy: 0.291000\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:     2.0856 Validation Accuracy: 0.282400\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:     1.9809 Validation Accuracy: 0.339800\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:     1.9409 Validation Accuracy: 0.319600\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:     1.6679 Validation Accuracy: 0.373000\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:     1.5743 Validation Accuracy: 0.390000\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:     1.4705 Validation Accuracy: 0.421600\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:     1.3414 Validation Accuracy: 0.431000\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:     1.2732 Validation Accuracy: 0.438200\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:     1.2232 Validation Accuracy: 0.464400\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:     1.1314 Validation Accuracy: 0.468000\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:     1.0910 Validation Accuracy: 0.468800\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:     1.1026 Validation Accuracy: 0.430600\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:     0.9725 Validation Accuracy: 0.474400\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:     0.9216 Validation Accuracy: 0.460600\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:     0.9305 Validation Accuracy: 0.496400\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:     0.8618 Validation Accuracy: 0.475800\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:     0.8032 Validation Accuracy: 0.488800\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:     0.8478 Validation Accuracy: 0.464200\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:     0.7946 Validation Accuracy: 0.467600\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:     0.8111 Validation Accuracy: 0.462800\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:     0.7117 Validation Accuracy: 0.492600\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:     0.7043 Validation Accuracy: 0.485000\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:     0.7025 Validation Accuracy: 0.495800\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:     0.7628 Validation Accuracy: 0.473800\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:     0.6279 Validation Accuracy: 0.487600\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:     0.5951 Validation Accuracy: 0.499000\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:     0.5882 Validation Accuracy: 0.461800\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:     0.6181 Validation Accuracy: 0.455000\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:     0.6216 Validation Accuracy: 0.494400\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:     0.5732 Validation Accuracy: 0.496400\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:     0.5660 Validation Accuracy: 0.497600\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:     0.6146 Validation Accuracy: 0.458200\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:     0.5267 Validation Accuracy: 0.474000\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:     0.4782 Validation Accuracy: 0.485800\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:     0.4614 Validation Accuracy: 0.483200\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:     0.4686 Validation Accuracy: 0.480200\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:     0.4525 Validation Accuracy: 0.476800\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:     0.4540 Validation Accuracy: 0.491000\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:     0.4216 Validation Accuracy: 0.510600\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:     0.3916 Validation Accuracy: 0.496000\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:     0.4032 Validation Accuracy: 0.493800\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:     0.3951 Validation Accuracy: 0.479400\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:     0.3811 Validation Accuracy: 0.497400\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:     0.4043 Validation Accuracy: 0.486200\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:     0.4014 Validation Accuracy: 0.481400\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:     0.3835 Validation Accuracy: 0.491800\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss:     0.3923 Validation Accuracy: 0.502400\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss:     0.3758 Validation Accuracy: 0.474800\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss:     0.3751 Validation Accuracy: 0.494000\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss:     0.3638 Validation Accuracy: 0.487800\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss:     0.3675 Validation Accuracy: 0.470200\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss:     0.3594 Validation Accuracy: 0.470800\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss:     0.3526 Validation Accuracy: 0.468400\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss:     0.3538 Validation Accuracy: 0.483800\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss:     0.3528 Validation Accuracy: 0.491000\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss:     0.3375 Validation Accuracy: 0.495800\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss:     0.3349 Validation Accuracy: 0.492600\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss:     0.3665 Validation Accuracy: 0.432600\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss:     0.4384 Validation Accuracy: 0.435400\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss:     0.3224 Validation Accuracy: 0.488400\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss:     0.3365 Validation Accuracy: 0.482800\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss:     0.3340 Validation Accuracy: 0.472800\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss:     0.3169 Validation Accuracy: 0.472400\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss:     0.3280 Validation Accuracy: 0.480200\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss:     0.3162 Validation Accuracy: 0.495000\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss:     0.3040 Validation Accuracy: 0.470600\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 完全训练模型\n",
    "\n",
    "现在，单个 CIFAR-10 部分的准确率已经不错了，试试所有五个部分吧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:     2.2742 Validation Accuracy: 0.143400\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss:     2.2277 Validation Accuracy: 0.194800\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss:     2.0964 Validation Accuracy: 0.214600\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss:     2.1244 Validation Accuracy: 0.258200\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss:     2.0575 Validation Accuracy: 0.289400\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:     2.0623 Validation Accuracy: 0.305600\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss:     2.0074 Validation Accuracy: 0.299600\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss:     1.8678 Validation Accuracy: 0.327600\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss:     1.9449 Validation Accuracy: 0.375600\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss:     1.8924 Validation Accuracy: 0.354200\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:     1.9313 Validation Accuracy: 0.394200\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss:     1.9013 Validation Accuracy: 0.378600\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss:     1.6546 Validation Accuracy: 0.405600\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss:     1.7903 Validation Accuracy: 0.408800\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss:     1.6722 Validation Accuracy: 0.393000\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:     1.7101 Validation Accuracy: 0.398400\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss:     1.7835 Validation Accuracy: 0.411600\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss:     1.6271 Validation Accuracy: 0.413600\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss:     1.6465 Validation Accuracy: 0.434800\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss:     1.5904 Validation Accuracy: 0.440600\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:     1.5810 Validation Accuracy: 0.442400\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss:     1.6718 Validation Accuracy: 0.445200\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss:     1.5343 Validation Accuracy: 0.452000\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss:     1.5377 Validation Accuracy: 0.436800\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss:     1.4902 Validation Accuracy: 0.460400\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:     1.5069 Validation Accuracy: 0.448600\n",
      "Epoch  6, CIFAR-10 Batch 2:  Loss:     1.5546 Validation Accuracy: 0.455200\n",
      "Epoch  6, CIFAR-10 Batch 3:  Loss:     1.4449 Validation Accuracy: 0.458800\n",
      "Epoch  6, CIFAR-10 Batch 4:  Loss:     1.5124 Validation Accuracy: 0.467400\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss:     1.2498 Validation Accuracy: 0.452200\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:     1.4120 Validation Accuracy: 0.453000\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss:     1.6270 Validation Accuracy: 0.438400\n",
      "Epoch  7, CIFAR-10 Batch 3:  Loss:     1.4320 Validation Accuracy: 0.450200\n",
      "Epoch  7, CIFAR-10 Batch 4:  Loss:     1.4374 Validation Accuracy: 0.476400\n",
      "Epoch  7, CIFAR-10 Batch 5:  Loss:     1.2699 Validation Accuracy: 0.480600\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:     1.3249 Validation Accuracy: 0.477200\n",
      "Epoch  8, CIFAR-10 Batch 2:  Loss:     1.4729 Validation Accuracy: 0.478800\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss:     1.3743 Validation Accuracy: 0.466200\n",
      "Epoch  8, CIFAR-10 Batch 4:  Loss:     1.3797 Validation Accuracy: 0.476000\n",
      "Epoch  8, CIFAR-10 Batch 5:  Loss:     1.2207 Validation Accuracy: 0.484800\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:     1.2638 Validation Accuracy: 0.470600\n",
      "Epoch  9, CIFAR-10 Batch 2:  Loss:     1.4061 Validation Accuracy: 0.492200\n",
      "Epoch  9, CIFAR-10 Batch 3:  Loss:     1.3333 Validation Accuracy: 0.470600\n",
      "Epoch  9, CIFAR-10 Batch 4:  Loss:     1.3410 Validation Accuracy: 0.486600\n",
      "Epoch  9, CIFAR-10 Batch 5:  Loss:     1.1543 Validation Accuracy: 0.499200\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:     1.2534 Validation Accuracy: 0.474800\n",
      "Epoch 10, CIFAR-10 Batch 2:  Loss:     1.3849 Validation Accuracy: 0.499000\n",
      "Epoch 10, CIFAR-10 Batch 3:  Loss:     1.2808 Validation Accuracy: 0.469800\n",
      "Epoch 10, CIFAR-10 Batch 4:  Loss:     1.2478 Validation Accuracy: 0.489200\n",
      "Epoch 10, CIFAR-10 Batch 5:  Loss:     1.1816 Validation Accuracy: 0.493000\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:     1.1206 Validation Accuracy: 0.483400\n",
      "Epoch 11, CIFAR-10 Batch 2:  Loss:     1.3209 Validation Accuracy: 0.507200\n",
      "Epoch 11, CIFAR-10 Batch 3:  Loss:     1.1708 Validation Accuracy: 0.489400\n",
      "Epoch 11, CIFAR-10 Batch 4:  Loss:     1.2096 Validation Accuracy: 0.494000\n",
      "Epoch 11, CIFAR-10 Batch 5:  Loss:     1.0811 Validation Accuracy: 0.491200\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:     1.0756 Validation Accuracy: 0.502800\n",
      "Epoch 12, CIFAR-10 Batch 2:  Loss:     1.2847 Validation Accuracy: 0.496000\n",
      "Epoch 12, CIFAR-10 Batch 3:  Loss:     1.1311 Validation Accuracy: 0.480000\n",
      "Epoch 12, CIFAR-10 Batch 4:  Loss:     1.1514 Validation Accuracy: 0.512200\n",
      "Epoch 12, CIFAR-10 Batch 5:  Loss:     1.0204 Validation Accuracy: 0.512600\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:     1.1081 Validation Accuracy: 0.510600\n",
      "Epoch 13, CIFAR-10 Batch 2:  Loss:     1.3231 Validation Accuracy: 0.494200\n",
      "Epoch 13, CIFAR-10 Batch 3:  Loss:     1.1623 Validation Accuracy: 0.513200\n",
      "Epoch 13, CIFAR-10 Batch 4:  Loss:     1.1658 Validation Accuracy: 0.518800\n",
      "Epoch 13, CIFAR-10 Batch 5:  Loss:     1.0052 Validation Accuracy: 0.493000\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:     0.9815 Validation Accuracy: 0.496800\n",
      "Epoch 14, CIFAR-10 Batch 2:  Loss:     1.2705 Validation Accuracy: 0.499200\n",
      "Epoch 14, CIFAR-10 Batch 3:  Loss:     1.1530 Validation Accuracy: 0.515200\n",
      "Epoch 14, CIFAR-10 Batch 4:  Loss:     1.1546 Validation Accuracy: 0.497000\n",
      "Epoch 14, CIFAR-10 Batch 5:  Loss:     0.9629 Validation Accuracy: 0.513600\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:     0.9729 Validation Accuracy: 0.506600\n",
      "Epoch 15, CIFAR-10 Batch 2:  Loss:     1.2220 Validation Accuracy: 0.503600\n",
      "Epoch 15, CIFAR-10 Batch 3:  Loss:     1.1455 Validation Accuracy: 0.494600\n",
      "Epoch 15, CIFAR-10 Batch 4:  Loss:     1.0285 Validation Accuracy: 0.526800\n",
      "Epoch 15, CIFAR-10 Batch 5:  Loss:     0.9160 Validation Accuracy: 0.521600\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:     1.0075 Validation Accuracy: 0.508400\n",
      "Epoch 16, CIFAR-10 Batch 2:  Loss:     1.2449 Validation Accuracy: 0.464600\n",
      "Epoch 16, CIFAR-10 Batch 3:  Loss:     1.1104 Validation Accuracy: 0.524000\n",
      "Epoch 16, CIFAR-10 Batch 4:  Loss:     0.9948 Validation Accuracy: 0.524400\n",
      "Epoch 16, CIFAR-10 Batch 5:  Loss:     0.8809 Validation Accuracy: 0.501400\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:     0.9454 Validation Accuracy: 0.514400\n",
      "Epoch 17, CIFAR-10 Batch 2:  Loss:     1.1453 Validation Accuracy: 0.490000\n",
      "Epoch 17, CIFAR-10 Batch 3:  Loss:     1.0855 Validation Accuracy: 0.519200\n",
      "Epoch 17, CIFAR-10 Batch 4:  Loss:     0.9425 Validation Accuracy: 0.535800\n",
      "Epoch 17, CIFAR-10 Batch 5:  Loss:     0.9105 Validation Accuracy: 0.526200\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:     0.8802 Validation Accuracy: 0.521400\n",
      "Epoch 18, CIFAR-10 Batch 2:  Loss:     1.0855 Validation Accuracy: 0.514200\n",
      "Epoch 18, CIFAR-10 Batch 3:  Loss:     1.0568 Validation Accuracy: 0.536000\n",
      "Epoch 18, CIFAR-10 Batch 4:  Loss:     0.9247 Validation Accuracy: 0.544000\n",
      "Epoch 18, CIFAR-10 Batch 5:  Loss:     0.8463 Validation Accuracy: 0.527400\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:     0.8953 Validation Accuracy: 0.534800\n",
      "Epoch 19, CIFAR-10 Batch 2:  Loss:     1.1414 Validation Accuracy: 0.492200\n",
      "Epoch 19, CIFAR-10 Batch 3:  Loss:     1.0538 Validation Accuracy: 0.519000\n",
      "Epoch 19, CIFAR-10 Batch 4:  Loss:     0.9249 Validation Accuracy: 0.529000\n",
      "Epoch 19, CIFAR-10 Batch 5:  Loss:     0.8222 Validation Accuracy: 0.531400\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:     0.8766 Validation Accuracy: 0.538400\n",
      "Epoch 20, CIFAR-10 Batch 2:  Loss:     1.0626 Validation Accuracy: 0.497800\n",
      "Epoch 20, CIFAR-10 Batch 3:  Loss:     1.0126 Validation Accuracy: 0.544400\n",
      "Epoch 20, CIFAR-10 Batch 4:  Loss:     0.8980 Validation Accuracy: 0.530400\n",
      "Epoch 20, CIFAR-10 Batch 5:  Loss:     0.8905 Validation Accuracy: 0.508800\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:     0.9316 Validation Accuracy: 0.496600\n",
      "Epoch 21, CIFAR-10 Batch 2:  Loss:     1.0294 Validation Accuracy: 0.499200\n",
      "Epoch 21, CIFAR-10 Batch 3:  Loss:     0.9973 Validation Accuracy: 0.528800\n",
      "Epoch 21, CIFAR-10 Batch 4:  Loss:     0.8827 Validation Accuracy: 0.555200\n",
      "Epoch 21, CIFAR-10 Batch 5:  Loss:     0.7843 Validation Accuracy: 0.542200\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:     0.8044 Validation Accuracy: 0.544800\n",
      "Epoch 22, CIFAR-10 Batch 2:  Loss:     1.0163 Validation Accuracy: 0.526000\n",
      "Epoch 22, CIFAR-10 Batch 3:  Loss:     0.9700 Validation Accuracy: 0.536200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, CIFAR-10 Batch 4:  Loss:     0.8640 Validation Accuracy: 0.533200\n",
      "Epoch 22, CIFAR-10 Batch 5:  Loss:     0.7744 Validation Accuracy: 0.529000\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:     0.8018 Validation Accuracy: 0.534800\n",
      "Epoch 23, CIFAR-10 Batch 2:  Loss:     1.0373 Validation Accuracy: 0.511800\n",
      "Epoch 23, CIFAR-10 Batch 3:  Loss:     0.9614 Validation Accuracy: 0.555600\n",
      "Epoch 23, CIFAR-10 Batch 4:  Loss:     0.8584 Validation Accuracy: 0.539200\n",
      "Epoch 23, CIFAR-10 Batch 5:  Loss:     0.7540 Validation Accuracy: 0.555600\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:     0.7830 Validation Accuracy: 0.525000\n",
      "Epoch 24, CIFAR-10 Batch 2:  Loss:     0.9364 Validation Accuracy: 0.545200\n",
      "Epoch 24, CIFAR-10 Batch 3:  Loss:     0.9214 Validation Accuracy: 0.555000\n",
      "Epoch 24, CIFAR-10 Batch 4:  Loss:     0.7597 Validation Accuracy: 0.557800\n",
      "Epoch 24, CIFAR-10 Batch 5:  Loss:     0.7161 Validation Accuracy: 0.557200\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:     0.8251 Validation Accuracy: 0.503800\n",
      "Epoch 25, CIFAR-10 Batch 2:  Loss:     0.9381 Validation Accuracy: 0.537600\n",
      "Epoch 25, CIFAR-10 Batch 3:  Loss:     0.9112 Validation Accuracy: 0.556800\n",
      "Epoch 25, CIFAR-10 Batch 4:  Loss:     0.8170 Validation Accuracy: 0.541200\n",
      "Epoch 25, CIFAR-10 Batch 5:  Loss:     0.7219 Validation Accuracy: 0.543200\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:     0.7526 Validation Accuracy: 0.561200\n",
      "Epoch 26, CIFAR-10 Batch 2:  Loss:     0.9172 Validation Accuracy: 0.551200\n",
      "Epoch 26, CIFAR-10 Batch 3:  Loss:     0.8932 Validation Accuracy: 0.549400\n",
      "Epoch 26, CIFAR-10 Batch 4:  Loss:     0.7690 Validation Accuracy: 0.553200\n",
      "Epoch 26, CIFAR-10 Batch 5:  Loss:     0.6712 Validation Accuracy: 0.558400\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:     0.7832 Validation Accuracy: 0.560200\n",
      "Epoch 27, CIFAR-10 Batch 2:  Loss:     0.9002 Validation Accuracy: 0.531000\n",
      "Epoch 27, CIFAR-10 Batch 3:  Loss:     0.8782 Validation Accuracy: 0.557400\n",
      "Epoch 27, CIFAR-10 Batch 4:  Loss:     0.7723 Validation Accuracy: 0.532400\n",
      "Epoch 27, CIFAR-10 Batch 5:  Loss:     0.6732 Validation Accuracy: 0.539600\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:     0.7472 Validation Accuracy: 0.553800\n",
      "Epoch 28, CIFAR-10 Batch 2:  Loss:     0.8667 Validation Accuracy: 0.560400\n",
      "Epoch 28, CIFAR-10 Batch 3:  Loss:     0.8733 Validation Accuracy: 0.547400\n",
      "Epoch 28, CIFAR-10 Batch 4:  Loss:     0.7131 Validation Accuracy: 0.558400\n",
      "Epoch 28, CIFAR-10 Batch 5:  Loss:     0.6405 Validation Accuracy: 0.549400\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:     0.7529 Validation Accuracy: 0.522200\n",
      "Epoch 29, CIFAR-10 Batch 2:  Loss:     0.9120 Validation Accuracy: 0.556000\n",
      "Epoch 29, CIFAR-10 Batch 3:  Loss:     0.8746 Validation Accuracy: 0.525400\n",
      "Epoch 29, CIFAR-10 Batch 4:  Loss:     0.7349 Validation Accuracy: 0.520800\n",
      "Epoch 29, CIFAR-10 Batch 5:  Loss:     0.6331 Validation Accuracy: 0.569600\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:     0.6954 Validation Accuracy: 0.566800\n",
      "Epoch 30, CIFAR-10 Batch 2:  Loss:     0.9763 Validation Accuracy: 0.567800\n",
      "Epoch 30, CIFAR-10 Batch 3:  Loss:     0.8679 Validation Accuracy: 0.542600\n",
      "Epoch 30, CIFAR-10 Batch 4:  Loss:     0.7601 Validation Accuracy: 0.541600\n",
      "Epoch 30, CIFAR-10 Batch 5:  Loss:     0.6612 Validation Accuracy: 0.559400\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:     0.7301 Validation Accuracy: 0.570600\n",
      "Epoch 31, CIFAR-10 Batch 2:  Loss:     0.8337 Validation Accuracy: 0.565200\n",
      "Epoch 31, CIFAR-10 Batch 3:  Loss:     0.8878 Validation Accuracy: 0.554000\n",
      "Epoch 31, CIFAR-10 Batch 4:  Loss:     0.6811 Validation Accuracy: 0.562600\n",
      "Epoch 31, CIFAR-10 Batch 5:  Loss:     0.6594 Validation Accuracy: 0.567600\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:     0.7055 Validation Accuracy: 0.557000\n",
      "Epoch 32, CIFAR-10 Batch 2:  Loss:     0.8344 Validation Accuracy: 0.563600\n",
      "Epoch 32, CIFAR-10 Batch 3:  Loss:     0.8008 Validation Accuracy: 0.551200\n",
      "Epoch 32, CIFAR-10 Batch 4:  Loss:     0.6726 Validation Accuracy: 0.558000\n",
      "Epoch 32, CIFAR-10 Batch 5:  Loss:     0.6151 Validation Accuracy: 0.556000\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:     0.6534 Validation Accuracy: 0.565800\n",
      "Epoch 33, CIFAR-10 Batch 2:  Loss:     0.7826 Validation Accuracy: 0.577200\n",
      "Epoch 33, CIFAR-10 Batch 3:  Loss:     0.8167 Validation Accuracy: 0.562200\n",
      "Epoch 33, CIFAR-10 Batch 4:  Loss:     0.6542 Validation Accuracy: 0.566200\n",
      "Epoch 33, CIFAR-10 Batch 5:  Loss:     0.6096 Validation Accuracy: 0.554200\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:     0.6201 Validation Accuracy: 0.576600\n",
      "Epoch 34, CIFAR-10 Batch 2:  Loss:     0.8026 Validation Accuracy: 0.558200\n",
      "Epoch 34, CIFAR-10 Batch 3:  Loss:     0.8104 Validation Accuracy: 0.557400\n",
      "Epoch 34, CIFAR-10 Batch 4:  Loss:     0.6664 Validation Accuracy: 0.564000\n",
      "Epoch 34, CIFAR-10 Batch 5:  Loss:     0.5777 Validation Accuracy: 0.548000\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:     0.6177 Validation Accuracy: 0.566400\n",
      "Epoch 35, CIFAR-10 Batch 2:  Loss:     0.7396 Validation Accuracy: 0.569400\n",
      "Epoch 35, CIFAR-10 Batch 3:  Loss:     0.7820 Validation Accuracy: 0.567200\n",
      "Epoch 35, CIFAR-10 Batch 4:  Loss:     0.6485 Validation Accuracy: 0.559800\n",
      "Epoch 35, CIFAR-10 Batch 5:  Loss:     0.5596 Validation Accuracy: 0.550200\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:     0.6743 Validation Accuracy: 0.569200\n",
      "Epoch 36, CIFAR-10 Batch 2:  Loss:     0.7367 Validation Accuracy: 0.568400\n",
      "Epoch 36, CIFAR-10 Batch 3:  Loss:     0.7667 Validation Accuracy: 0.576000\n",
      "Epoch 36, CIFAR-10 Batch 4:  Loss:     0.6419 Validation Accuracy: 0.553000\n",
      "Epoch 36, CIFAR-10 Batch 5:  Loss:     0.5262 Validation Accuracy: 0.563800\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:     0.6412 Validation Accuracy: 0.563400\n",
      "Epoch 37, CIFAR-10 Batch 2:  Loss:     0.6848 Validation Accuracy: 0.575800\n",
      "Epoch 37, CIFAR-10 Batch 3:  Loss:     0.7802 Validation Accuracy: 0.578200\n",
      "Epoch 37, CIFAR-10 Batch 4:  Loss:     0.5823 Validation Accuracy: 0.568600\n",
      "Epoch 37, CIFAR-10 Batch 5:  Loss:     0.5241 Validation Accuracy: 0.568800\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:     0.6072 Validation Accuracy: 0.565400\n",
      "Epoch 38, CIFAR-10 Batch 2:  Loss:     0.6799 Validation Accuracy: 0.579200\n",
      "Epoch 38, CIFAR-10 Batch 3:  Loss:     0.7831 Validation Accuracy: 0.576200\n",
      "Epoch 38, CIFAR-10 Batch 4:  Loss:     0.5749 Validation Accuracy: 0.566000\n",
      "Epoch 38, CIFAR-10 Batch 5:  Loss:     0.5180 Validation Accuracy: 0.578400\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:     0.6404 Validation Accuracy: 0.551800\n",
      "Epoch 39, CIFAR-10 Batch 2:  Loss:     0.6816 Validation Accuracy: 0.568400\n",
      "Epoch 39, CIFAR-10 Batch 3:  Loss:     0.7720 Validation Accuracy: 0.582000\n",
      "Epoch 39, CIFAR-10 Batch 4:  Loss:     0.5731 Validation Accuracy: 0.569200\n",
      "Epoch 39, CIFAR-10 Batch 5:  Loss:     0.5047 Validation Accuracy: 0.580400\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:     0.5884 Validation Accuracy: 0.560600\n",
      "Epoch 40, CIFAR-10 Batch 2:  Loss:     0.6554 Validation Accuracy: 0.577200\n",
      "Epoch 40, CIFAR-10 Batch 3:  Loss:     0.7451 Validation Accuracy: 0.581000\n",
      "Epoch 40, CIFAR-10 Batch 4:  Loss:     0.5625 Validation Accuracy: 0.567400\n",
      "Epoch 40, CIFAR-10 Batch 5:  Loss:     0.5090 Validation Accuracy: 0.570000\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:     0.5264 Validation Accuracy: 0.569600\n",
      "Epoch 41, CIFAR-10 Batch 2:  Loss:     0.6524 Validation Accuracy: 0.582200\n",
      "Epoch 41, CIFAR-10 Batch 3:  Loss:     0.7173 Validation Accuracy: 0.588200\n",
      "Epoch 41, CIFAR-10 Batch 4:  Loss:     0.5087 Validation Accuracy: 0.555200\n",
      "Epoch 41, CIFAR-10 Batch 5:  Loss:     0.4872 Validation Accuracy: 0.563800\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:     0.5190 Validation Accuracy: 0.572800\n",
      "Epoch 42, CIFAR-10 Batch 2:  Loss:     0.6155 Validation Accuracy: 0.575600\n",
      "Epoch 42, CIFAR-10 Batch 3:  Loss:     0.7095 Validation Accuracy: 0.583600\n",
      "Epoch 42, CIFAR-10 Batch 4:  Loss:     0.4972 Validation Accuracy: 0.579800\n",
      "Epoch 42, CIFAR-10 Batch 5:  Loss:     0.4451 Validation Accuracy: 0.583200\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:     0.5430 Validation Accuracy: 0.576800\n",
      "Epoch 43, CIFAR-10 Batch 2:  Loss:     0.6051 Validation Accuracy: 0.583200\n",
      "Epoch 43, CIFAR-10 Batch 3:  Loss:     0.6904 Validation Accuracy: 0.581000\n",
      "Epoch 43, CIFAR-10 Batch 4:  Loss:     0.4881 Validation Accuracy: 0.561400\n",
      "Epoch 43, CIFAR-10 Batch 5:  Loss:     0.4505 Validation Accuracy: 0.576400\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:     0.5458 Validation Accuracy: 0.570200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44, CIFAR-10 Batch 2:  Loss:     0.6137 Validation Accuracy: 0.583600\n",
      "Epoch 44, CIFAR-10 Batch 3:  Loss:     0.6922 Validation Accuracy: 0.586000\n",
      "Epoch 44, CIFAR-10 Batch 4:  Loss:     0.4951 Validation Accuracy: 0.574600\n",
      "Epoch 44, CIFAR-10 Batch 5:  Loss:     0.4302 Validation Accuracy: 0.583000\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:     0.4958 Validation Accuracy: 0.576800\n",
      "Epoch 45, CIFAR-10 Batch 2:  Loss:     0.6009 Validation Accuracy: 0.572200\n",
      "Epoch 45, CIFAR-10 Batch 3:  Loss:     0.6712 Validation Accuracy: 0.589800\n",
      "Epoch 45, CIFAR-10 Batch 4:  Loss:     0.4697 Validation Accuracy: 0.574600\n",
      "Epoch 45, CIFAR-10 Batch 5:  Loss:     0.4100 Validation Accuracy: 0.586600\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:     0.5075 Validation Accuracy: 0.581400\n",
      "Epoch 46, CIFAR-10 Batch 2:  Loss:     0.5850 Validation Accuracy: 0.578800\n",
      "Epoch 46, CIFAR-10 Batch 3:  Loss:     0.6730 Validation Accuracy: 0.585800\n",
      "Epoch 46, CIFAR-10 Batch 4:  Loss:     0.4714 Validation Accuracy: 0.581000\n",
      "Epoch 46, CIFAR-10 Batch 5:  Loss:     0.4043 Validation Accuracy: 0.584800\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:     0.4683 Validation Accuracy: 0.584600\n",
      "Epoch 47, CIFAR-10 Batch 2:  Loss:     0.5770 Validation Accuracy: 0.576000\n",
      "Epoch 47, CIFAR-10 Batch 3:  Loss:     0.7176 Validation Accuracy: 0.583000\n",
      "Epoch 47, CIFAR-10 Batch 4:  Loss:     0.5037 Validation Accuracy: 0.575600\n",
      "Epoch 47, CIFAR-10 Batch 5:  Loss:     0.3928 Validation Accuracy: 0.578000\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:     0.4777 Validation Accuracy: 0.571000\n",
      "Epoch 48, CIFAR-10 Batch 2:  Loss:     0.5919 Validation Accuracy: 0.570200\n",
      "Epoch 48, CIFAR-10 Batch 3:  Loss:     0.6922 Validation Accuracy: 0.569200\n",
      "Epoch 48, CIFAR-10 Batch 4:  Loss:     0.4558 Validation Accuracy: 0.572000\n",
      "Epoch 48, CIFAR-10 Batch 5:  Loss:     0.3832 Validation Accuracy: 0.586400\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:     0.4596 Validation Accuracy: 0.578200\n",
      "Epoch 49, CIFAR-10 Batch 2:  Loss:     0.5865 Validation Accuracy: 0.567200\n",
      "Epoch 49, CIFAR-10 Batch 3:  Loss:     0.6677 Validation Accuracy: 0.573800\n",
      "Epoch 49, CIFAR-10 Batch 4:  Loss:     0.4692 Validation Accuracy: 0.563600\n",
      "Epoch 49, CIFAR-10 Batch 5:  Loss:     0.3680 Validation Accuracy: 0.593200\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:     0.4573 Validation Accuracy: 0.579800\n",
      "Epoch 50, CIFAR-10 Batch 2:  Loss:     0.5726 Validation Accuracy: 0.571600\n",
      "Epoch 50, CIFAR-10 Batch 3:  Loss:     0.6675 Validation Accuracy: 0.574600\n",
      "Epoch 50, CIFAR-10 Batch 4:  Loss:     0.4471 Validation Accuracy: 0.585200\n",
      "Epoch 50, CIFAR-10 Batch 5:  Loss:     0.3864 Validation Accuracy: 0.591600\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss:     0.4419 Validation Accuracy: 0.580400\n",
      "Epoch 51, CIFAR-10 Batch 2:  Loss:     0.5289 Validation Accuracy: 0.580800\n",
      "Epoch 51, CIFAR-10 Batch 3:  Loss:     0.6266 Validation Accuracy: 0.588600\n",
      "Epoch 51, CIFAR-10 Batch 4:  Loss:     0.4147 Validation Accuracy: 0.583400\n",
      "Epoch 51, CIFAR-10 Batch 5:  Loss:     0.3555 Validation Accuracy: 0.596200\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss:     0.4049 Validation Accuracy: 0.588200\n",
      "Epoch 52, CIFAR-10 Batch 2:  Loss:     0.5570 Validation Accuracy: 0.571200\n",
      "Epoch 52, CIFAR-10 Batch 3:  Loss:     0.5992 Validation Accuracy: 0.595800\n",
      "Epoch 52, CIFAR-10 Batch 4:  Loss:     0.4267 Validation Accuracy: 0.584600\n",
      "Epoch 52, CIFAR-10 Batch 5:  Loss:     0.3695 Validation Accuracy: 0.594200\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss:     0.4063 Validation Accuracy: 0.589600\n",
      "Epoch 53, CIFAR-10 Batch 2:  Loss:     0.5208 Validation Accuracy: 0.582400\n",
      "Epoch 53, CIFAR-10 Batch 3:  Loss:     0.5701 Validation Accuracy: 0.586400\n",
      "Epoch 53, CIFAR-10 Batch 4:  Loss:     0.4238 Validation Accuracy: 0.585800\n",
      "Epoch 53, CIFAR-10 Batch 5:  Loss:     0.3557 Validation Accuracy: 0.595600\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss:     0.3963 Validation Accuracy: 0.585200\n",
      "Epoch 54, CIFAR-10 Batch 2:  Loss:     0.5169 Validation Accuracy: 0.576200\n",
      "Epoch 54, CIFAR-10 Batch 3:  Loss:     0.5544 Validation Accuracy: 0.585600\n",
      "Epoch 54, CIFAR-10 Batch 4:  Loss:     0.4226 Validation Accuracy: 0.569400\n",
      "Epoch 54, CIFAR-10 Batch 5:  Loss:     0.3713 Validation Accuracy: 0.592400\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss:     0.4106 Validation Accuracy: 0.593200\n",
      "Epoch 55, CIFAR-10 Batch 2:  Loss:     0.5243 Validation Accuracy: 0.586000\n",
      "Epoch 55, CIFAR-10 Batch 3:  Loss:     0.5613 Validation Accuracy: 0.577400\n",
      "Epoch 55, CIFAR-10 Batch 4:  Loss:     0.3933 Validation Accuracy: 0.596400\n",
      "Epoch 55, CIFAR-10 Batch 5:  Loss:     0.3378 Validation Accuracy: 0.600000\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss:     0.3953 Validation Accuracy: 0.593600\n",
      "Epoch 56, CIFAR-10 Batch 2:  Loss:     0.5327 Validation Accuracy: 0.578600\n",
      "Epoch 56, CIFAR-10 Batch 3:  Loss:     0.5458 Validation Accuracy: 0.583600\n",
      "Epoch 56, CIFAR-10 Batch 4:  Loss:     0.3890 Validation Accuracy: 0.590000\n",
      "Epoch 56, CIFAR-10 Batch 5:  Loss:     0.3341 Validation Accuracy: 0.586600\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss:     0.4066 Validation Accuracy: 0.589600\n",
      "Epoch 57, CIFAR-10 Batch 2:  Loss:     0.5100 Validation Accuracy: 0.590800\n",
      "Epoch 57, CIFAR-10 Batch 3:  Loss:     0.5743 Validation Accuracy: 0.585400\n",
      "Epoch 57, CIFAR-10 Batch 4:  Loss:     0.5694 Validation Accuracy: 0.581800\n",
      "Epoch 57, CIFAR-10 Batch 5:  Loss:     0.3269 Validation Accuracy: 0.601800\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss:     0.3870 Validation Accuracy: 0.582000\n",
      "Epoch 58, CIFAR-10 Batch 2:  Loss:     0.4972 Validation Accuracy: 0.592400\n",
      "Epoch 58, CIFAR-10 Batch 3:  Loss:     0.5403 Validation Accuracy: 0.586800\n",
      "Epoch 58, CIFAR-10 Batch 4:  Loss:     0.3780 Validation Accuracy: 0.593000\n",
      "Epoch 58, CIFAR-10 Batch 5:  Loss:     0.3181 Validation Accuracy: 0.593600\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss:     0.4499 Validation Accuracy: 0.582600\n",
      "Epoch 59, CIFAR-10 Batch 2:  Loss:     0.5059 Validation Accuracy: 0.576000\n",
      "Epoch 59, CIFAR-10 Batch 3:  Loss:     0.5438 Validation Accuracy: 0.589200\n",
      "Epoch 59, CIFAR-10 Batch 4:  Loss:     0.3964 Validation Accuracy: 0.582000\n",
      "Epoch 59, CIFAR-10 Batch 5:  Loss:     0.3106 Validation Accuracy: 0.597000\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss:     0.3646 Validation Accuracy: 0.594600\n",
      "Epoch 60, CIFAR-10 Batch 2:  Loss:     0.4817 Validation Accuracy: 0.584200\n",
      "Epoch 60, CIFAR-10 Batch 3:  Loss:     0.5431 Validation Accuracy: 0.590000\n",
      "Epoch 60, CIFAR-10 Batch 4:  Loss:     0.3915 Validation Accuracy: 0.594200\n",
      "Epoch 60, CIFAR-10 Batch 5:  Loss:     0.4373 Validation Accuracy: 0.592200\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss:     0.3691 Validation Accuracy: 0.574000\n",
      "Epoch 61, CIFAR-10 Batch 2:  Loss:     0.5593 Validation Accuracy: 0.569000\n",
      "Epoch 61, CIFAR-10 Batch 3:  Loss:     0.5292 Validation Accuracy: 0.598400\n",
      "Epoch 61, CIFAR-10 Batch 4:  Loss:     0.4474 Validation Accuracy: 0.584600\n",
      "Epoch 61, CIFAR-10 Batch 5:  Loss:     0.3180 Validation Accuracy: 0.590200\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss:     0.3925 Validation Accuracy: 0.572600\n",
      "Epoch 62, CIFAR-10 Batch 2:  Loss:     0.5002 Validation Accuracy: 0.585600\n",
      "Epoch 62, CIFAR-10 Batch 3:  Loss:     0.5527 Validation Accuracy: 0.565200\n",
      "Epoch 62, CIFAR-10 Batch 4:  Loss:     0.3717 Validation Accuracy: 0.594400\n",
      "Epoch 62, CIFAR-10 Batch 5:  Loss:     0.3145 Validation Accuracy: 0.585600\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss:     0.3758 Validation Accuracy: 0.573000\n",
      "Epoch 63, CIFAR-10 Batch 2:  Loss:     0.4923 Validation Accuracy: 0.586400\n",
      "Epoch 63, CIFAR-10 Batch 3:  Loss:     0.5228 Validation Accuracy: 0.596800\n",
      "Epoch 63, CIFAR-10 Batch 4:  Loss:     0.3669 Validation Accuracy: 0.600200\n",
      "Epoch 63, CIFAR-10 Batch 5:  Loss:     0.3019 Validation Accuracy: 0.599000\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss:     0.3563 Validation Accuracy: 0.589000\n",
      "Epoch 64, CIFAR-10 Batch 2:  Loss:     0.4779 Validation Accuracy: 0.590200\n",
      "Epoch 64, CIFAR-10 Batch 3:  Loss:     0.5250 Validation Accuracy: 0.591800\n",
      "Epoch 64, CIFAR-10 Batch 4:  Loss:     0.3608 Validation Accuracy: 0.595800\n",
      "Epoch 64, CIFAR-10 Batch 5:  Loss:     0.3294 Validation Accuracy: 0.582800\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss:     0.3721 Validation Accuracy: 0.580400\n",
      "Epoch 65, CIFAR-10 Batch 2:  Loss:     0.4695 Validation Accuracy: 0.587800\n",
      "Epoch 65, CIFAR-10 Batch 3:  Loss:     0.5285 Validation Accuracy: 0.588400\n",
      "Epoch 65, CIFAR-10 Batch 4:  Loss:     0.4116 Validation Accuracy: 0.575800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65, CIFAR-10 Batch 5:  Loss:     0.3071 Validation Accuracy: 0.594800\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss:     0.3672 Validation Accuracy: 0.576800\n",
      "Epoch 66, CIFAR-10 Batch 2:  Loss:     0.4738 Validation Accuracy: 0.585800\n",
      "Epoch 66, CIFAR-10 Batch 3:  Loss:     0.5303 Validation Accuracy: 0.588400\n",
      "Epoch 66, CIFAR-10 Batch 4:  Loss:     0.3499 Validation Accuracy: 0.591600\n",
      "Epoch 66, CIFAR-10 Batch 5:  Loss:     0.3090 Validation Accuracy: 0.592000\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss:     0.3531 Validation Accuracy: 0.591000\n",
      "Epoch 67, CIFAR-10 Batch 2:  Loss:     0.4783 Validation Accuracy: 0.584600\n",
      "Epoch 67, CIFAR-10 Batch 3:  Loss:     0.5366 Validation Accuracy: 0.594400\n",
      "Epoch 67, CIFAR-10 Batch 4:  Loss:     0.3590 Validation Accuracy: 0.589600\n",
      "Epoch 67, CIFAR-10 Batch 5:  Loss:     0.3047 Validation Accuracy: 0.588600\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss:     0.3719 Validation Accuracy: 0.587000\n",
      "Epoch 68, CIFAR-10 Batch 2:  Loss:     0.4803 Validation Accuracy: 0.588000\n",
      "Epoch 68, CIFAR-10 Batch 3:  Loss:     0.5184 Validation Accuracy: 0.584400\n",
      "Epoch 68, CIFAR-10 Batch 4:  Loss:     0.3840 Validation Accuracy: 0.579600\n",
      "Epoch 68, CIFAR-10 Batch 5:  Loss:     0.3247 Validation Accuracy: 0.581800\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss:     0.3567 Validation Accuracy: 0.597800\n",
      "Epoch 69, CIFAR-10 Batch 2:  Loss:     0.4755 Validation Accuracy: 0.586600\n",
      "Epoch 69, CIFAR-10 Batch 3:  Loss:     0.5122 Validation Accuracy: 0.573200\n",
      "Epoch 69, CIFAR-10 Batch 4:  Loss:     0.3457 Validation Accuracy: 0.593200\n",
      "Epoch 69, CIFAR-10 Batch 5:  Loss:     0.2848 Validation Accuracy: 0.595400\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss:     0.3534 Validation Accuracy: 0.592800\n",
      "Epoch 70, CIFAR-10 Batch 2:  Loss:     0.4802 Validation Accuracy: 0.574000\n",
      "Epoch 70, CIFAR-10 Batch 3:  Loss:     0.5186 Validation Accuracy: 0.561600\n",
      "Epoch 70, CIFAR-10 Batch 4:  Loss:     0.3532 Validation Accuracy: 0.590600\n",
      "Epoch 70, CIFAR-10 Batch 5:  Loss:     0.2904 Validation Accuracy: 0.587600\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查点\n",
    "\n",
    "模型已保存到本地。\n",
    "\n",
    "## 测试模型\n",
    "\n",
    "利用测试数据集测试你的模型。这将是最终的准确率。你的准确率应该高于 50%。如果没达到，请继续调整模型结构和参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./image_classification\n",
      "Testing Accuracy: 0.58564453125\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiIiIpEGxyIiIiIi0f8HR4HOSjY4Wy8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1220eab38>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_test.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for test_feature_batch, test_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 为何准确率只有50-80%？\n",
    "\n",
    "你可能想问，为何准确率不能更高了？首先，对于简单的 CNN 网络来说，50% 已经不低了。纯粹猜测的准确率为10%。但是，你可能注意到有人的准确率[远远超过 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130)。这是因为我们还没有介绍所有的神经网络知识。我们还需要掌握一些其他技巧。\n",
    "\n",
    "## 提交项目\n",
    "\n",
    "提交项目时，确保先运行所有单元，然后再保存记事本。将 notebook 文件另存为“dlnd_image_classification.ipynb”，再在目录 \"File\" -> \"Download as\" 另存为 HTML 格式。请在提交的项目中包含 “helper.py” 和 “problem_unittests.py” 文件。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
